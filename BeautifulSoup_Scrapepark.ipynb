{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup\n",
    "\n",
    "- **Documentación oficial:** https://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "\n",
    "- **página que utilizaremos:**  https://scrapepark.org/spanish/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de BeautifulSoup: 4.12.2\n",
      "Versión de requests: 2.31.0\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías para ver la versión\n",
    "import requests\n",
    "import bs4 \n",
    "print(f'Versión de BeautifulSoup: {bs4.__version__}')\n",
    "print(f'Versión de requests: {requests.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Obtener el HTML\n",
    "URL_BASE = 'https://scrapepark.org/courses/spanish/'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. \"Parsear\" ese HTML\n",
    "soup = BeautifulSoup(html_obtenido, \"html.parser\")\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método find()\n",
    "\n",
    "Nos permite obtener la información de la primera etiqueta HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2>¿Por qué comprar con nosotros?</h2>\n"
     ]
    }
   ],
   "source": [
    "primer_h2 = soup.find('h2')\n",
    "print(primer_h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos solo el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Por qué comprar con nosotros?\n",
      "¿Por qué comprar con nosotros?\n"
     ]
    }
   ],
   "source": [
    "print(primer_h2.text)\n",
    "\n",
    "# equivalente a:\n",
    "print(soup.h2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método find_all()\n",
    "Obtenemos TODOS los elementos de la página con la etiqueta y devuelve una \"lista\" que los contiene (en realidad devuelve un objeto de la clase bs4.element.ResultSet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2>¿Por qué comprar con nosotros?</h2>, <h2>\n",
      "                  #Novedades\n",
      "                </h2>, <h2>\n",
      "            Nuestros <span>productos</span>\n",
      "</h2>, <h2>\n",
      "            Testimonios de clientes\n",
      "          </h2>, <h2 class=\"heading-container\">\n",
      "          Tabla de precios\n",
      "        </h2>]\n"
     ]
    }
   ],
   "source": [
    "h2_todos = soup.find_all('h2')\n",
    "print(h2_todos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: ¿Por qué comprar con nosotros?\n",
      "Texto: #Novedades\n",
      "Texto: Nuestrosproductos\n",
      "Texto: Testimonios de clientes\n",
      "Texto: Tabla de precios\n"
     ]
    }
   ],
   "source": [
    "for etiqueta in h2_todos:\n",
    "    print(f'Texto: {etiqueta.get_text(strip = True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien podemos utilizar el argumento LIMIT para reducir la busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2>¿Por qué comprar con nosotros?</h2>]\n"
     ]
    }
   ],
   "source": [
    "h2_uno_solo = soup.find_all('h2',limit=1)\n",
    "print(h2_uno_solo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: ¿Por qué comprar con nosotros?\n",
      "Texto: \n",
      "                  #Novedades\n",
      "                \n",
      "Texto: \n",
      "            Nuestros productos\n",
      "\n",
      "Texto: \n",
      "            Testimonios de clientes\n",
      "          \n",
      "Texto: \n",
      "          Tabla de precios\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Podemos iterar sobre el objeto\n",
    "for etiqueta in h2_todos:\n",
    "    print(f'Texto: {etiqueta.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Por qué comprar con nosotros?\n",
      "#Novedades\n",
      "Nuestrosproductos\n",
      "Testimonios de clientes\n",
      "Tabla de precios\n"
     ]
    }
   ],
   "source": [
    "# get_text() para más funcionalidades\n",
    "# Eliminar todos los espacios adelante y atras\n",
    "for seccion in h2_todos:\n",
    "  print(seccion.get_text(strip=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando atributos de las etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accediendo a una clase específica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"heading-container heading-center\" id=\"acerca\">\n",
      "<h2>¿Por qué comprar con nosotros?</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\" id=\"productos\">\n",
      "<h2>\n",
      "            Nuestros <span>productos</span>\n",
      "</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h3>Suscríbete para obtener descuentos y ofertas</h3>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h2>\n",
      "            Testimonios de clientes\n",
      "          </h2>\n",
      "</div>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Clase\n",
    "divs = soup.find_all('div', class_ = \"heading-container heading-center\")\n",
    "\n",
    "for div in divs:\n",
    "  print(div)\n",
    "  print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"Parque de patinaje\" src=\"images/slider-bg.jpg\"/>\n",
      "<img alt=\"Patineta 2\" src=\"images/p2.jpg\"/>\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos todas las etiquetas que tengan el atributo \"src\" \n",
    "src_todos = soup.find_all(src=True)\n",
    "\n",
    "# Seleccionamos solo las que terminen con .jpg\n",
    "for elemento in src_todos:\n",
    "  if elemento['src'].endswith(\".jpg\"):\n",
    "    print(elemento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/arrival-bg-store.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/p1.png\n",
      "images/p3.png\n",
      "images/p4.png\n",
      "images/p5.png\n",
      "images/p6.png\n",
      "images/p7.png\n",
      "images/p8.png\n",
      "images/p9.png\n",
      "images/p10.png\n",
      "images/p11.png\n",
      "images/p12.png\n",
      "images/client-one.png\n",
      "images/client-two.png\n",
      "images/client-three.png\n",
      "./images/freecodecamp-logo.png\n"
     ]
    }
   ],
   "source": [
    "# Descargamos todas las imagenes\n",
    "url_imagenes = []\n",
    "\n",
    "for i, imagen in enumerate(src_todos):\n",
    "\n",
    "  if imagen['src'].endswith('png'):\n",
    "\n",
    "    print(imagen['src'])\n",
    "    r = requests.get(f\"https://scrapepark.org/courses/spanish/{imagen['src']}\")\n",
    "\n",
    "    with open(f'imagen_{i}.png', 'wb') as f:\n",
    "      f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que iframe nos redirecciona a una página diferente, primero tenemos que obtener la página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'table.html'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debido a que find_all devuelve más de un elemento con [0] elegimos el primero\n",
    "soup.find_all('iframe')[0]['src']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya la tenemos, accedemos directamente a la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información de tablas\n",
    "URL_BASE = 'https://scrapepark.org/courses/spanish'\n",
    "URL_TABLA = soup.find_all('iframe')[0]['src']\n",
    "\n",
    "request_tabla = requests.get(f'{URL_BASE}/{URL_TABLA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-bordered table-striped table-hover\">\n",
       "<thead class=\"thead-dark\">\n",
       "<tr>\n",
       "<th> </th>\n",
       "<th class=\"text-center\">Skate</th>\n",
       "<th class=\"text-center\">Cruiser</th>\n",
       "<th class=\"text-center\" style=\"color: red;\">Longboard</th>\n",
       "<th class=\"text-center\">Freeboard</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>Azul</td>\n",
       "<td class=\"text-center\">$64</td>\n",
       "<td class=\"text-center\">$70</td>\n",
       "<td class=\"text-center\" style=\"color: red;\">$80</td>\n",
       "<td class=\"text-center\">$85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Verde</td>\n",
       "<td class=\"text-center\">$69</td>\n",
       "<td class=\"text-center\">$75</td>\n",
       "<td class=\"text-center\" style=\"color: red;\">$85</td>\n",
       "<td class=\"text-center\">$90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Negro</td>\n",
       "<td class=\"text-center\">$74</td>\n",
       "<td class=\"text-center\">$80</td>\n",
       "<td class=\"text-center\" style=\"color: red;\">$90</td>\n",
       "<td class=\"text-center\">$95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Morado</td>\n",
       "<td class=\"text-center\">$55</td>\n",
       "<td class=\"text-center\">$60</td>\n",
       "<td class=\"text-center\" style=\"color: red;\">$62</td>\n",
       "<td class=\"text-center\">$72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Especial</td>\n",
       "<td class=\"text-center\">$110</td>\n",
       "<td class=\"text-center\">$125</td>\n",
       "<td class=\"text-center\" style=\"color: red;\">$150</td>\n",
       "<td class=\"text-center\">$167</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Volvemos a utilzar BeautifulSoup para poder acceder a los datos con find\n",
    "html_tabla = request_tabla.text\n",
    "soup_tabla = BeautifulSoup(html_tabla, \"html.parser\")\n",
    "soup_tabla.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Longboard', '$80', '$85', '$90', '$62', '$150']\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos todas las filas y columnas pero tambien las obtenemos por el color \n",
    "productos_faltantes = soup_tabla.find_all(['th', 'td'], attrs={'style':'color: red;'})\n",
    "productos_faltantes = [talle.text for talle in productos_faltantes]\n",
    "\n",
    "print(productos_faltantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obteniendo los productos y precios de los artículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producto: Patineta Nueva 1  | precio: 75\n",
      "producto: Patineta Usada 2  | precio: 80\n",
      "producto: Patineta Nueva 3  | precio: 68\n",
      "producto: Patineta Usada 4  | precio: 70\n",
      "producto: Patineta Nueva 5  | precio: 75\n",
      "producto: Patineta Nueva 6  | precio: 58\n",
      "producto: Patineta Nueva 7  | precio: 80\n",
      "producto: Patineta Nueva 8  | precio: 35\n",
      "producto: Patineta Nueva 9  | precio: 165\n",
      "producto: Patineta Usada 10 | precio: 54\n",
      "producto: Patineta Usada 11 | precio: 99\n",
      "producto: Patineta Nueva 12 | precio: 110\n"
     ]
    }
   ],
   "source": [
    "divs = soup.find_all('div', class_='detail-box')\n",
    "productos = []\n",
    "precios = []\n",
    "\n",
    "for div in divs:\n",
    "  if (div.h6 is not None) and ('Patineta' in div.h5.text):\n",
    "    producto = div.h5.get_text(strip=True)\n",
    "    precio = div.h6.get_text(strip=True).replace('$', '')\n",
    "    # Se puede agregar filtros\n",
    "    print(f'producto: {producto:<17} | precio: {precio}')\n",
    "    productos.append(producto)\n",
    "    precios.append(precio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URL's que contienen cambios pequeños"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tenemos una URL que cambia entre contactos (contacto1, contacto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scrapepark.org/courses/spanish/contact1\n",
      "Texto que cambia entre páginas en contacto 1 :)\n",
      "https://scrapepark.org/courses/spanish/contact2\n",
      "Texto que cambia entre páginas en contacto 2 :)\n"
     ]
    }
   ],
   "source": [
    "URL_BASE = \"https://scrapepark.org/courses/spanish/contact\"\n",
    "\n",
    "for i in range(1,3):\n",
    "  URL_FINAL = f\"{URL_BASE}{i}\"\n",
    "  print(URL_FINAL)\n",
    "  r = requests.get(URL_FINAL)\n",
    "  soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "  print(soup.h5.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos que no sabemos en que parte de la página se encuentran\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizamos expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 4-444-4444']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expresiones regulares\n",
    "import re\n",
    "\n",
    "# 1. Obtener el HTML\n",
    "URL_BASE = 'https://scrapepark.org/courses/spanish'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text\n",
    "\n",
    "# 2. \"Parsear\" ese HTML\n",
    "soup = BeautifulSoup(html_obtenido, \"html.parser\")\n",
    "\n",
    "telefonos = soup.find_all(string=re.compile(r\"\\d+-\\d+-\\d+\"))\n",
    "telefonos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moviéndonos por el árbol\n",
    "\n",
    "Para saber más: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'© 2022 '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copyrights = soup.find_all(string=re.compile(\"©\"))\n",
    "copyrights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos navegar por el arbol. Si queremos ir a ver al padre de la equiqueta utilizamos .parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'© 2022 '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primer_copyright = copyrights[0]\n",
    "primer_copyright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>© 2022 <span>Todos los derechos reservados</span>.\n",
       "        <a href=\"https://html.design/\" rel=\"noopener noreferrer\" target=\"_blank\">Creado con Free Html Templates</a>.\n",
       "      </p>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primer_copyright = copyrights[0]\n",
    "primer_copyright.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul>\n",
       " <li><a href=\"#\">Inicio</a></li>\n",
       " <li><a href=\"#\">Acerca</a></li>\n",
       " <li><a href=\"#\">Servicios</a></li>\n",
       " <li><a href=\"#\">Testimonios</a></li>\n",
       " <li><a href=\"#\">Contacto</a></li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Otro ejemplo con elementos al mismo nivel\n",
    "menu = soup.find(string=re.compile(\"MENÚ\"))\n",
    "# menu.parent\n",
    "menu.parent.find_next_siblings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario sobre excepciones (Try except)\n",
    "https://docs.python.org/es/3/tutorial/errors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENÚ\n",
      "© 2022 \n",
      "El string 'carpincho' no fue encontrado\n",
      "\n",
      "                  Patineta Nueva 1\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "strings_a_buscar = [\"MENÚ\", \"©\", \"carpincho\", \"Patineta\"]\n",
    "\n",
    "for string in strings_a_buscar:\n",
    "  try:\n",
    "    resultado = soup.find(string=re.compile(string))\n",
    "    print(resultado.text)\n",
    "  except AttributeError:\n",
    "    print(f\"El string '{string}' no fue encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Almacenamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "productos.insert(0, \"productos\")\n",
    "precios.insert(0, \"precios\")\n",
    "# datos = dict(zip(productos, precios))\n",
    "     \n",
    "\n",
    "datos = dict(zip(productos, precios))\n",
    "     \n",
    "\n",
    "datos.items()\n",
    "     \n",
    "\n",
    "import csv\n",
    "\n",
    "with open('datos.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(datos.items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
