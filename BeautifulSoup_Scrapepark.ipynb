{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup\n",
    "\n",
    "- **Documentación oficial:** https://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "\n",
    "- **página que utilizaremos:**  https://scrapepark.org/spanish/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de BeautifulSoup: 4.12.2\n",
      "Versión de requests: 2.31.0\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías para ver la versión\n",
    "import requests\n",
    "import bs4 \n",
    "print(f'Versión de BeautifulSoup: {bs4.__version__}')\n",
    "print(f'Versión de requests: {requests.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Obtener el HTML\n",
    "URL_BASE = 'https://scrapepark.org/courses/spanish/'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. \"Parsear\" ese HTML\n",
    "soup = BeautifulSoup(html_obtenido, \"html.parser\")\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El método find()\n",
    "Nos permite quedarnos con la información asociada a una etiqueta de HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2>¿Por qué comprar con nosotros?</h2>\n"
     ]
    }
   ],
   "source": [
    "primer_h2 = soup.find('h2')\n",
    "print(primer_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Por qué comprar con nosotros?\n",
      "¿Por qué comprar con nosotros?\n"
     ]
    }
   ],
   "source": [
    "# Solo el texto\n",
    "print(primer_h2.text)\n",
    "\n",
    "# equivalente a:\n",
    "print(soup.h2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El método find_all()\n",
    "Busca TODOS los elementos de la página con esa etiqueta y devuelve una \"lista\" que los contiene (en realidad devuelve un objeto de la clase bs4.element.ResultSet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2>¿Por qué comprar con nosotros?</h2>, <h2>\n",
      "                  #Novedades\n",
      "                </h2>, <h2>\n",
      "            Nuestros <span>productos</span>\n",
      "</h2>, <h2>\n",
      "            Testimonios de clientes\n",
      "          </h2>, <h2 class=\"heading-container\">\n",
      "          Tabla de precios\n",
      "        </h2>]\n"
     ]
    }
   ],
   "source": [
    "h2_todos = soup.find_all('h2')\n",
    "print(h2_todos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2>¿Por qué comprar con nosotros?</h2>]\n",
      "¿Por qué comprar con nosotros?\n",
      "\n",
      "                  #Novedades\n",
      "                \n",
      "\n",
      "            Nuestros productos\n",
      "\n",
      "\n",
      "            Testimonios de clientes\n",
      "          \n",
      "\n",
      "          Tabla de precios\n",
      "        \n",
      "¿Por qué comprar con nosotros?\n",
      "#Novedades\n",
      "Nuestrosproductos\n",
      "Testimonios de clientes\n",
      "Tabla de precios\n"
     ]
    }
   ],
   "source": [
    "# ARGUMENTOS\n",
    "# Si usamos el parametro limit = 1, emulamos al metodo find\n",
    "h2_uno_solo = soup.find_all('h2',limit=1)\n",
    "print(h2_uno_solo)\n",
    "     \n",
    "\n",
    "# Podemos iterar sobre el objeto\n",
    "for seccion in h2_todos:\n",
    "  print(seccion.text)\n",
    "     \n",
    "\n",
    "# get_text() para más funcionalidades\n",
    "for seccion in h2_todos:\n",
    "  print(seccion.get_text(strip=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando atributos de las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"heading-container heading-center\" id=\"acerca\">\n",
      "<h2>¿Por qué comprar con nosotros?</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\" id=\"productos\">\n",
      "<h2>\n",
      "            Nuestros <span>productos</span>\n",
      "</h2>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h3>Suscríbete para obtener descuentos y ofertas</h3>\n",
      "</div>\n",
      " \n",
      "<div class=\"heading-container heading-center\">\n",
      "<h2>\n",
      "            Testimonios de clientes\n",
      "          </h2>\n",
      "</div>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Clase\n",
    "divs = soup.find_all('div', class_ = \"heading-container heading-center\")\n",
    "\n",
    "for div in divs:\n",
    "  print(div)\n",
    "  print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"Parque de patinaje\" src=\"images/slider-bg.jpg\"/>\n",
      "<img alt=\"Patineta 2\" src=\"images/p2.jpg\"/>\n"
     ]
    }
   ],
   "source": [
    "# Todas las etiquetas que tengan el atributo \"src\"\n",
    "src_todos = soup.find_all(src=True)\n",
    "\n",
    "for elemento in src_todos:\n",
    "  if elemento['src'].endswith(\".jpg\"):\n",
    "    print(elemento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/arrival-bg-store.png\n",
      "images/p1.png\n",
      "images/p3.png\n",
      "images/p4.png\n",
      "images/p5.png\n",
      "images/p6.png\n",
      "images/p7.png\n",
      "images/p8.png\n",
      "images/p9.png\n",
      "images/p10.png\n",
      "images/p11.png\n",
      "images/p12.png\n",
      "images/client-one.png\n",
      "images/client-two.png\n",
      "images/client-three.png\n",
      "./images/freecodecamp-logo.png\n"
     ]
    }
   ],
   "source": [
    "#@title Ejercicio: Bajar todas las imagenes!\n",
    "\n",
    "url_imagenes = []\n",
    "\n",
    "for i, imagen in enumerate(src_todos):\n",
    "\n",
    "  if imagen['src'].endswith('png'):\n",
    "\n",
    "    print(imagen['src'])\n",
    "    r = requests.get(f\"https://scrapepark.org/courses/spanish/{imagen['src']}\")\n",
    "\n",
    "    with open(f'imagen_{i}.png', 'wb') as f:\n",
    "      f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Longboard', '$80', '$85', '$90', '$62', '$150']\n",
      "producto: Patineta Nueva 1 | precio: 75\n",
      "producto: Patineta Usada 2 | precio: 80\n",
      "producto: Patineta Nueva 3 | precio: 68\n",
      "producto: Patineta Usada 4 | precio: 70\n",
      "producto: Patineta Nueva 5 | precio: 75\n",
      "producto: Patineta Nueva 6 | precio: 58\n",
      "producto: Patineta Nueva 7 | precio: 80\n",
      "producto: Patineta Nueva 8 | precio: 35\n",
      "producto: Patineta Nueva 9 | precio: 165\n",
      "producto: Patineta Usada 10 | precio: 54\n",
      "producto: Patineta Usada 11 | precio: 99\n",
      "producto: Patineta Nueva 12 | precio: 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Patineta Nueva 1',\n",
       " 'Patineta Usada 2',\n",
       " 'Patineta Nueva 3',\n",
       " 'Patineta Usada 4',\n",
       " 'Patineta Nueva 5',\n",
       " 'Patineta Nueva 6',\n",
       " 'Patineta Nueva 7',\n",
       " 'Patineta Nueva 8',\n",
       " 'Patineta Nueva 9',\n",
       " 'Patineta Usada 10',\n",
       " 'Patineta Usada 11',\n",
       " 'Patineta Nueva 12']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('iframe')[0]['src']\n",
    "\n",
    "# Información de tablas\n",
    "\n",
    "URL_BASE = 'https://scrapepark.org/courses/spanish'\n",
    "URL_TABLA = soup.find_all('iframe')[0]['src']\n",
    "\n",
    "request_tabla = requests.get(f'{URL_BASE}/{URL_TABLA}')\n",
    "\n",
    "html_tabla = request_tabla.text\n",
    "soup_tabla = BeautifulSoup(html_tabla, \"html.parser\")\n",
    "soup_tabla.find('table')\n",
    "\n",
    "productos_faltantes = soup_tabla.find_all(['th', 'td'], attrs={'style':'color: red;'})\n",
    "productos_faltantes = [talle.text for talle in productos_faltantes]\n",
    "\n",
    "print(productos_faltantes)\n",
    "     \n",
    "\n",
    "divs = soup.find_all('div', class_='detail-box')\n",
    "productos = []\n",
    "precios = []\n",
    "\n",
    "for div in divs:\n",
    "  if (div.h6 is not None) and ('Patineta' in div.h5.text):\n",
    "    producto = div.h5.get_text(strip=True)\n",
    "    precio = div.h6.get_text(strip=True).replace('$', '')\n",
    "    # Se puede agregar filtros\n",
    "    print(f'producto: {producto:<16} | precio: {precio}')\n",
    "    productos.append(producto)\n",
    "    precios.append(precio)\n",
    "     \n",
    "\n",
    "precios\n",
    "     \n",
    "['75', '80', '68', '70', '75', '58', '80', '35', '165', '54', '99', '110']\n",
    "\n",
    "productos\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cambios que dependen de la URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scrapepark.org/courses/spanish/contact1\n",
      "Texto que cambia entre páginas en contacto 1 :)\n",
      "https://scrapepark.org/courses/spanish/contact2\n",
      "Texto que cambia entre páginas en contacto 2 :)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "URL_BASE = \"https://scrapepark.org/courses/spanish/contact\"\n",
    "\n",
    "for i in range(1,3):\n",
    "  URL_FINAL = f\"{URL_BASE}{i}\"\n",
    "  print(URL_FINAL)\n",
    "  r = requests.get(URL_FINAL)\n",
    "  soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "  print(soup.h5.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos que no sabemos en que parte de la página se encuentran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Jose Fuentes\\AppData\\Local\\Temp\\ipykernel_24224\\1181429916.py:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  telefonos = soup.find_all(string=re.compile(\"\\d+-\\d+-\\d+\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' 4-444-4444']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expresiones regulares\n",
    "import re\n",
    "\n",
    "# 1. Obtener el HTML\n",
    "URL_BASE = 'https://scrapepark.org/courses/spanish'\n",
    "pedido_obtenido = requests.get(URL_BASE)\n",
    "html_obtenido = pedido_obtenido.text\n",
    "\n",
    "# 2. \"Parsear\" ese HTML\n",
    "soup = BeautifulSoup(html_obtenido, \"html.parser\")\n",
    "\n",
    "telefonos = soup.find_all(string=re.compile(\"\\d+-\\d+-\\d+\"))\n",
    "telefonos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moviéndonos por el árbol\n",
    "\n",
    "Para saber más: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul>\n",
       " <li><a href=\"#\">Inicio</a></li>\n",
       " <li><a href=\"#\">Acerca</a></li>\n",
       " <li><a href=\"#\">Servicios</a></li>\n",
       " <li><a href=\"#\">Testimonios</a></li>\n",
       " <li><a href=\"#\">Contacto</a></li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copyrights = soup.find_all(string=re.compile(\"©\"))\n",
    "copyrights[0]\n",
    "     \n",
    "\n",
    "primer_copyright = copyrights[0]\n",
    "primer_copyright.parent\n",
    "     \n",
    "\n",
    "# # Otro ejemplo con elementos al mismo nivel\n",
    "menu = soup.find(string=re.compile(\"MENÚ\"))\n",
    "# menu.parent\n",
    "menu.parent.find_next_siblings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comentario sobre excepciones\n",
    "https://docs.python.org/es/3/tutorial/errors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENÚ\n",
      "© 2022 \n",
      "El string 'carpincho' no fue encontrado\n",
      "\n",
      "                  Patineta Nueva 1\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "strings_a_buscar = [\"MENÚ\", \"©\", \"carpincho\", \"Patineta\"]\n",
    "\n",
    "for string in strings_a_buscar:\n",
    "  try:\n",
    "    resultado = soup.find(string=re.compile(string))\n",
    "    print(resultado.text)\n",
    "  except AttributeError:\n",
    "    print(f\"El string '{string}' no fue encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Almacenamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "productos.insert(0, \"productos\")\n",
    "precios.insert(0, \"precios\")\n",
    "# datos = dict(zip(productos, precios))\n",
    "     \n",
    "\n",
    "datos = dict(zip(productos, precios))\n",
    "     \n",
    "\n",
    "datos.items()\n",
    "     \n",
    "\n",
    "import csv\n",
    "\n",
    "with open('datos.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(datos.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS! Algunos ejercicios para seguir practicando:\n",
    "\n",
    "Las patinetas que salgan menos que $68\n",
    "Las patinetas que en su nombre tengan un numero mayor a 3\n",
    "Traer cualquier texto de la pagina que tenga la palabra descuento u oferta.\n",
    "Generar un archivo .csv con dos columnas: Una conteniendo el nombre del cliente y otra su testimonio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
